# 카프카

## 카프카란?

- 분산형 데이터 스트리밍 시스템
- 대규모 데이터 실시간 스트리밍에 유용하게 사용된다.
- 로그 수집, MSA, 실시간 통계 등 비동기 처리가 필요한 서비스에 활용

## 주요 특징

- Producer
    - 카프카 브로커에 메시지를 저장하는 역할
- Consumer
    - 카프카 브로커에 저장된 메시지를 읽는 역할
    - Consumer Group
        - 하나의 메시지를 여러 Consumer에서 읽기 위한 그룹
        - 같은 파티션의 메시지를 그룹 내에서 중복으로 읽지 않음
        
        | Partition | Group A (C1, C2) | Group B (C3) |
        | --- | --- | --- |
        | P0 | C1 | C3 |
        | P1 | C2 | C3 |
        - Consumer = Partition
            
            각 Consumer가 하나의 Partition을 전담, 가장 이상적인 구조로 최적의 병렬 처리 가능
            
            | C1 | P1 |
            | --- | --- |
            | C2 | P2 |
            | C3 | P3 |
        - Consumer < Partition
            
            일부 Consumer가 여러 Partition을 담당
            
            | C1 | P1 |
            | --- | --- |
            | C1 | P2 |
            | C2 | P3 |
        - Consumer > Partition
            
            일부 Consumer는 할당 없이 대기
            
            | C1 | P1 |
            | --- | --- |
            | C2 | P2 |
            | C3 |  |
- Broker
    - 카프카 클러스터를 구성하는 서버를 의미
    - Producer로 부터 메시지를 받아서 저장
    - Consumer에게 필요한 데이터를 전달
- Topic
    - 메시지를 분류하는 단위
    - Producer가 메시지를 발행하고, Consumer가 메시지를 소비하는 곳
    - N개의 Partition으로 구성
- Partition
    - 하나의 Topic을 나누는 물리적 단위
    - 나눠져 있는 Partition의 개수만큼 병렬 처리 가능 → 빠른 데이터 처리
    - 같은 Partition의 메세지에 대해서 순차 처리 보장
    
    | Topic | Partition |
    | --- | --- |
    | T1 | P0, P1, P2, P3 |
    | T2 | P0, P1 |
- Offset
    - 파티션 레코드들에 지정되어있는 일련번호
    - Consumer는 Offset을 확인하여 메시지를 어디까지 읽었는지 확인할 수 있다.
- Rebalancing
    - Consumer Group 내에서 파티션의 소유권이 변경되는 행위
        - 그룹 내에 새로운 Consumer가 추가 될 때.
        - 기존 Consumer가 사라질 때
        - Topic에 새로운 Partition이 추가 될 때
    - Rebalancing 진행 중에는 Consumer가 메시지를 읽을 수 없음 (중복 소비 등의 위험)
- Cluster
    - 여러 Broker로 구성된 시스템
    - Kafka의 고가용성, 확장성, 내결함성 보장
- Replication
    - 각 Partition 별로 Leader Replica, Follower Replica를 생성하여 장애 발생 시 백업으로 사용
        - Leader Replica
            
            각 Partition별로 하나 존재, 모든 Producer, Consumer는 Leader롤 통해 처리
            
        - Follower Replica
            
            Leader를 제외한 Replica, Leader의 메시지를 복제하여 백업, Leader 중단 시 Follower 중 하나가 새로운 Leader가 된다.

## 메시지 처리 흐름

![image](https://github.com/user-attachments/assets/4a033b59-077f-4cbe-aa00-2df52584d3fa)

- Producer에서 발행한 메시지를 Kafka Broker에 저장
- Consumer는 Kafka Broker에 저장 된 메시지를 읽어옴
    
    ( Kafka → Consumer 방향이 아닌 Kafka ← Consumer )
    
- Consumer가 메시지를 읽는 방식을 사용함으로서 Consumer가 데이터 처리량을 조절할 수 있기 때문에
    
    서버 부하가 생겼을 때 대처가 용이하다.

  ## 장애 발생 시 대응

### Out Box 패턴

- Kafka 이벤트를 발행 전 DB의 outbox 테이블에 발행 상태와 메시지 데이터를 저장
- Consumer에서 발행 된 메시지를 읽는데 성공 했을 경우 outbox 상태 값 변경 (start or receive 등)
- 비즈니스 로직이 성공하면 outbox 상태값 완료로 변경 (done)
- 일정 시간 간격으로 스케쥴러를 돌려 outbox를 확인하여 최초 상태값인 데이터 재시도 처리

## DLQ (Dead Letter Queue)

- 오류가 발생한 메시지를 따로 모아두는 큐
- 별도의 DLQ 토픽을 생성해서 사용.
- Consumer가 메시지를 받고 처리에 실패 했을 때 정해진 횟수 만큼 재시도 후 최종 실패 했을 때
    
    DLQ에 저장하여 관리
